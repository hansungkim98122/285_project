{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "This notebook is made to help pushing policies produced by TeachMyAgent's experiments on Hugging Face's Hub.\n",
    "## How to use this notebook\n",
    "This notebook is broken down into 4 sections:\n",
    "- **Imports**: import needed packages.\n",
    "- **Load data**: load results produced by experiments\n",
    "- **Functions definition**: define functions to compute and push top seeds for each experiment\n",
    "- **Push policies**: push policies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please install TensorflowJS with:\n",
    "`pip install tensorflowjs`\n",
    "\n",
    "**Warning: This will update your tensorflow version to >2. Please consider downgrading it back to be between 1.4 and 1.15.5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pylab\n",
    "import copy\n",
    "import re\n",
    "from enum import Enum\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.colorbar as cbar\n",
    "import seaborn as sns\n",
    "import imageio\n",
    "\n",
    "DIV_LINE_WIDTH = 50\n",
    "print(np.__version__)\n",
    "print(sys.executable)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from TeachMyAgent.students.run_logs_util import get_run_logs \n",
    "from TeachMyAgent.students.package_to_hub import package_to_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_datasets(rootdir, name_filter=None, rename_labels=False):\n",
    "    \"\"\"\n",
    "        Loads results of experiments.\n",
    " \n",
    "        Results to load can be filtered by their name and each experiment can be associated to a label (usually ACL method's name)\n",
    " \n",
    "        :param rootdir: Directory containing experiments to load (do not forget '/' at the end of the path)\n",
    "        :param name_filter: String experiments to load must contain\n",
    "        :param rename_labels: If True, each experiment will be associated to a label (see below). Labels are the names that will appear in plots.\n",
    "        :type rootdir: str\n",
    "        :type name_filter: str (or None)\n",
    "        :type rename_labels: boolean\n",
    "    \"\"\"\n",
    "    _, models_list, _ = next(os.walk(rootdir))\n",
    "    print(models_list)\n",
    "    for dir_name in models_list.copy():\n",
    "        if \"ignore\" in dir_name:\n",
    "            models_list.remove(dir_name)\n",
    "        if name_filter is not None and name_filter not in dir_name:\n",
    "            models_list.remove(dir_name)         \n",
    "        \n",
    "    for i,m_name in enumerate(models_list):           \n",
    "        print(\"extracting data for {}...\".format(m_name))\n",
    "        m_id = m_name\n",
    "        models_saves[m_id] = OrderedDict()\n",
    "        models_saves[m_id]['data'] = get_run_logs(rootdir+m_name, book_keeping_keys='*', min_len=0)\n",
    "        print(\"done\")\n",
    "        if m_name not in labels:\n",
    "            if not rename_labels:\n",
    "                labels[m_name] = m_name\n",
    "            else:\n",
    "                ##### MODIFY THIS IF YOU ADD A NEW METHOD #####\n",
    "                if 'ADR' in m_name:\n",
    "                    labels[m_name] = 'ADR'\n",
    "                elif 'ALP-GMM' in m_name:\n",
    "                    labels[m_name] = 'ALP-GMM'\n",
    "                elif 'Random' in m_name:\n",
    "                    labels[m_name] = 'Random'\n",
    "                elif 'Covar-GMM' in m_name:\n",
    "                    labels[m_name] = 'Covar-GMM'\n",
    "                elif 'RIAC' in m_name:\n",
    "                    labels[m_name] = 'RIAC'\n",
    "                elif 'GoalGAN' in m_name:\n",
    "                    labels[m_name] = 'GoalGAN'\n",
    "                elif 'Self-Paced' in m_name:\n",
    "                    labels[m_name] = 'Self-Paced'\n",
    "                elif 'Setter-Solver' in m_name:\n",
    "                    labels[m_name] = 'Setter-Solver'\n",
    "                elif 'UPPER_BASELINE' in m_name:\n",
    "                    labels[m_name] = 'UPPER_BASELINE'\n",
    "                else:\n",
    "                    labels[m_name] = m_name\n",
    "                ##### MODIFY THIS IF YOU ADD A NEW METHOD #####\n",
    "labels = OrderedDict()\n",
    "models_saves = OrderedDict()\n",
    "\n",
    "##### MODIFY THIS TO POINT TO YOUR DATA FOLDER #####\n",
    "data_folder = \"/home/cromac/Documents/Projects/TeachMyAgent/ACL-bench_repo/ACL_bench/data/OFFICIAL_RESULTS/BENCHMARK/\" # Please use an absolute path\n",
    "##### MODIFY THIS TO POINT TO YOUR DATA FOLDER #####\n",
    "\n",
    "get_datasets(data_folder, rename_labels=True, name_filter=\"parkour_ALP-GMM_walker_type_climbing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute top seeds per run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_seeds(expe_name, n):\n",
    "    \"\"\"\n",
    "        Calculate best seed of an experiment.\n",
    " \n",
    "        :param expe_name: Experiment's name\n",
    "        :param metric: Metric to use to calculate best seed\n",
    "        :type expe_name: str\n",
    "        :type metric: str\n",
    "        :return best seed, its metric value, mean of all seeds, std over seeds\n",
    "    \"\"\"\n",
    "    best_seed = -1\n",
    "    best_seed_value = -1000\n",
    "    runs_data = models_saves[expe_name]['data']\n",
    "    metric = 'evaluation return'\n",
    "    all_values = []\n",
    "    for run in runs_data:\n",
    "        if len(run[metric]) > 0:\n",
    "            data = run[metric][-1]\n",
    "            all_values.append(data)\n",
    "        else:\n",
    "            print(\"Skipping seed {}: no data\".format(run[\"config\"][\"seed\"]))\n",
    "            all_values.append(-100)\n",
    "            \n",
    "    sorted_indices = np.argsort(-1 * np.array(all_values))[:n]  # Compute top n indices\n",
    "    top_seeds = []\n",
    "    means, stds = [], []\n",
    "    for index in sorted_indices:\n",
    "        run = runs_data[index]\n",
    "        top_seeds.append(run[\"config\"][\"seed\"])\n",
    "        test_set_size = int(len(run['env_test_rewards'])/len(run['evaluation return']))\n",
    "        last_evaluation_results = run['env_test_rewards'][-test_set_size:]\n",
    "        means.append(np.mean(last_evaluation_results))\n",
    "        stds.append(np.std(last_evaluation_results))\n",
    "            \n",
    "    return top_seeds, means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_top_seeds_to_hub(n, experiment_id, base_hyperparameters, token, account):\n",
    "    label = labels[experiment_id]\n",
    "    morphology = experiment_id.split(\"walker_type_\")[1]\n",
    "    hyperparameters = copy.copy(base_hyperparameters)\n",
    "    hyperparameters[\"teacher\"] = label\n",
    "    hyperparameters[\"morphology\"] = morphology\n",
    "    top_seeds, means, stds = get_top_seeds(experiment_id, n)\n",
    "    for seed, mean_reward, std_reward in zip(top_seeds, means, stds):\n",
    "        _config = {}\n",
    "        _config[\"seed\"] = seed\n",
    "        _config[\"morphology\"] = morphologies_name_mapping[morphology]\n",
    "        _config[\"name\"] = f\"{label}_{hyperparameters['student']}_{_config['morphology']}_s{seed}\"\n",
    "        repo_name = f\"{account}/TA_{_config['name']}\"\n",
    "        model_path = os.path.join(data_folder, experiment_id, f\"{experiment_id}_s{seed}\")\n",
    "        print(f\"Uploading {repo_name}...\")\n",
    "        try:\n",
    "            package_to_hub(repo_name, _config, model_path, mean_reward, std_reward, hyperparameters, token)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = ''\n",
    "ACCOUNT = ''\n",
    "TOP_N = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphologies_name_mapping = {\n",
    "    'old_classic_bipedal': 'bipedal',\n",
    "    'climbing_profile_chimpanzee': 'chimpanzee',\n",
    "    'fish': 'fish'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(m_id,label) in enumerate(labels.items()):\n",
    "    push_top_seeds_to_hub(TOP_N, \n",
    "                      m_id, \n",
    "                      {\n",
    "                        'student': 'SAC', 'environment': 'parkour', 'training_steps': 20000000, 'n_evaluation_tasks': 100\n",
    "                      },\n",
    "                      TOKEN, ACCOUNT\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
