agent:
  base_config: sac_new
  env_name: parametric-continuous-parkour-v0
  exp_name: sac_new_parkour
  ep_len: 2000

  total_steps: 3000000
  random_steps: 10000
  training_starts: 10000

  batch_size: 256
  replay_buffer_capacity: 1000000
  training_freq: 1

  hidden_size: 256
  num_layers: 3

  #Actor params
  discount: 0.99
  actor_lr: 0.0001
  actor_update_frequency: 1
  alpha_lr: 0.0001
  alpha_betas: [0.9, 0.999]
  learnable_temperature: false
  init_temperature: 0.2 #alpha
  actor_betas: [0.9,0.999]
  actor_cfg:
    class: cs285.agents.critic.DoubleQCritic
    params:
      obs_dim: 36
      action_dim: 4
      hidden_dim: 256
      hidden_depth: 2

  #Critic params
  critic_lr: 0.0001
  critic_tau: 0.005
  critic_target_update_frequency: 1
  critic_betas: [0.9,0.999]
  critic_cfg: 
    class: cs285.agents.actor.DiagGaussianActor
    params:
      obs_dim: 36
      action_dim: 4
      hidden_depth: 2
      hidden_dim: 256
      log_std_bounds: [-5, 2]

# double_q_critic:
#   class: cs285.agents.critic.DoubleQCritic
#   params:
#     obs_dim: 36
#     action_dim: 4
#     hidden_dim: 512
#     hidden_depth: 2
    
# diag_gaussian_actor:
#   class: cs285.agents.actor.DiagGaussianActor
#   params:
#     obs_dim: 36
#     action_dim: 4
#     hidden_depth: 2
#     hidden_dim: 512
#     log_std_bounds: [-5, 2]


    
